{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import tools as tl\n",
    "import umap\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '../../datasets/BBC News/BBC News Train.csv'  # Replace with your actual file path\n",
    "bbc_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create the test set (735 rows) and training set (remaining rows)\n",
    "test_set = bbc_df.sample(n=735, random_state=42).reset_index(drop=True)  # Test set with 735 samples\n",
    "train_set = bbc_df.drop(test_set.index).reset_index(drop=True)  # Training set with remaining rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2031</td>\n",
       "      <td>uk young top euro earnings league british chil...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>tech helps disabled speed demons an organisati...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1860</td>\n",
       "      <td>camera phones are  must-haves  four times more...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       2031  uk young top euro earnings league british chil...  business\n",
       "1         76  tech helps disabled speed demons an organisati...      tech\n",
       "2       1860  camera phones are  must-haves  four times more...      tech"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 48/48 [00:45<00:00,  1.06batch/s]\n",
      "Generating Embeddings: 100%|██████████| 46/46 [00:45<00:00,  1.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/87/dhv__9sj0yv1kz0pfv2ds9nh0000gn/T/ipykernel_18189/994341711.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_test = torch.tensor(embeddings_test)\n",
      "/var/folders/87/dhv__9sj0yv1kz0pfv2ds9nh0000gn/T/ipykernel_18189/994341711.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_train = torch.tensor(embeddings_train)\n"
     ]
    }
   ],
   "source": [
    "# Initialize distilroberta tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
    "model = RobertaModel.from_pretrained('distilroberta-base')\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings_train = tl.generate_embeddings(train_set['Text'].tolist(), tokenizer, model)\n",
    "embeddings_test = tl.generate_embeddings(test_set['Text'].tolist(), tokenizer, model)\n",
    "\n",
    "embeddings_test = torch.tensor(embeddings_test)\n",
    "embeddings_train = torch.tensor(embeddings_train)\n",
    "print(\"Embeddings generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an SVM model to the reduced embeddings\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(embeddings_train, train_set['Category'])\n",
    "\n",
    "# Predict the labels\n",
    "predicted_labels = svm_model.predict(embeddings_test)\n",
    "\n",
    "# Add the predicted labels to the dataframe\n",
    "test_set['cluster'] = predicted_labels\n",
    "test_set['embedding'] = embeddings_test.tolist()\n",
    "\n",
    "train_set['embedding'] = embeddings_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.64%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (test_set['Category'] == test_set['cluster']).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

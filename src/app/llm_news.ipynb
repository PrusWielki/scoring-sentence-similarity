{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_community.llms import Ollama\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 20 newsgroups dataset\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "news_test = pd.DataFrame({'text': newsgroups_test.data, 'label': newsgroups_test.target})\n",
    "\n",
    "news_test['label'] = news_test['label'].map(lambda x: newsgroups_test.target_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  I am a little confused on all of the models of...       rec.autos\n",
       "1  I'm not familiar at all with the format of the...  comp.windows.x"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Defining Topics according to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = [\n",
    "'rec.autos (Discussions about cars and automobiles)', \n",
    " 'rec.motorcycles (Discussions about motorcycles and related topics)', \n",
    " 'rec.sport.baseball (Baseball teams, players, and games)', \n",
    " 'rec.sport.hockey (Hockey leagues, teams, and players)', \n",
    " 'soc.religion.christian (Christianity, its doctrines, and practices)', \n",
    " 'comp.sys.ibm.pc.hardware (IBM PC-compatible hardware and troubleshooting)', \n",
    " 'comp.graphics (Computer graphics, including rendering and 3D modeling)', \n",
    " 'comp.windows.x (The X Window System for graphical user interfaces on UNIX-like systems)',\n",
    " 'comp.sys.mac.hardware (Apple Macintosh hardware and troubleshooting)', \n",
    " 'comp.os.ms-windows.misc (Miscellaneous topics about Microsoft Windows)', \n",
    " 'talk.politics.guns (Gun politics, legislation, and rights)', \n",
    " 'talk.politics.misc (General political discussions)', \n",
    " 'talk.politics.mideast (Politics and current events in the Middle East)', \n",
    " 'talk.religion.misc (General religious discussions)', \n",
    " 'sci.med (Topics about medical science, health, and treatments)', \n",
    " 'sci.space (Space exploration, astronomy, and related science)', \n",
    " 'sci.crypt (Cryptography, including encryption and security techniques)', \n",
    " 'sci.electronics (Electronics, circuit design, and troubleshooting)',\n",
    " 'misc.forsale (Items for sale and related discussions)', \n",
    " 'alt.atheism (Debates and discussions about atheism and related topics)', \n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Assigning batches of dataset to Topics Generated in Step 2 and sentiment of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics_in_batches(input_df, topics, batch_size, llm=None):\n",
    "    \"\"\"\n",
    "    Assign topics to News Group in batches and update DataFrame directly.\n",
    "\n",
    "    Parameters:\n",
    "    input_df (pd.DataFrame): DataFrame containing Amazon reviews\n",
    "    topics (str): String of topics to assign from\n",
    "    batch_size (int): Number of reviews to process in each batch\n",
    "    llm: The language model instance to use for assigning topics\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with topic and sentiment assignments\n",
    "    \"\"\"\n",
    "    if llm is None:\n",
    "        raise ValueError(\"LLM instance must be provided\")\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Initialize Topic and Sentiment columns with 'Unknown'\n",
    "    df['Predicted Topic'] = 'Unknown'\n",
    "\n",
    "    total_df = len(df)\n",
    "\n",
    "    # Process reviews in batches with progress bar\n",
    "    for start_idx in tqdm(range(0, total_df, batch_size), desc=\"Assigning topics\"):\n",
    "        end_idx = min(start_idx + batch_size, total_df)\n",
    "        batch_news_list = df.iloc[start_idx:end_idx]\n",
    "        batch_news = \" \".join([f\"Item {i + 1}: {review},\" for i, review in enumerate(batch_news_list['text'])])\n",
    "        \n",
    "        # Generate prompt for current batch\n",
    "        prompt_assigning_prompt = f'''You are provided with news and helping to cluster them based on the topics.\n",
    "Please assign the news to the topics provided. Return only the name of the topic for the respective nwes.\n",
    "News can be found in tripletick block: ```{batch_news}```\n",
    "Topics to choose from: {topics}\n",
    "Please return in CSV format only topics for respective reviews and nothing else. Do not use triple backtick blocks. Only output exactly as on the example below:\n",
    "Example: Having an input of News1, News2, News3, News4, News5, ... NewsN\n",
    "Output: Topic1, Topic2, Topic3, Topic4, Topic5, ... TopicN\n",
    "'''\n",
    "        # Get assignments for current batch\n",
    "        result = llm.invoke(prompt_assigning_prompt, temperature=0.0)\n",
    "        try:\n",
    "            # Get assignments for current batch\n",
    "            result = llm.invoke(prompt_assigning_prompt, temperature=0.0)\n",
    "            \n",
    "            # Clean and split the result\n",
    "            result = result.strip()\n",
    "            if result.startswith('```') and result.endswith('```'):\n",
    "                result = result[3:-3].strip()\n",
    "            batch_assigned_topics = [topic.strip() for topic in result.split(',')]\n",
    "            \n",
    "            # Make sure we have the right number of topics\n",
    "            current_batch_size = len(batch_news)\n",
    "            \n",
    "            # Update each row individually to avoid alignment issues\n",
    "            for idx, topic in enumerate(batch_assigned_topics):\n",
    "                current_idx = start_idx + idx\n",
    "                if current_idx < len(df):\n",
    "                    df.iloc[current_idx, df.columns.get_loc('Predicted Topic')] = topic\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing batch {start_idx}-{end_idx}: {str(e)}\")\n",
    "            print(f\"Result received: {result}\")\n",
    "            print(f\"Batch size: {current_batch_size}\")\n",
    "            print(f\"Number of topics received: {len(batch_assigned_topics) if 'batch_assigned_topics' in locals() else 'N/A'}\")\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics: 100%|██████████| 50/50 [03:24<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "news_assigned = assign_topics_in_batches(\n",
    "    news_test.head(50),\n",
    "    topics=str(all_topics),\n",
    "    batch_size=1,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_assigned.to_csv('outputs/news_assigned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_assigned = pd.read_csv('outputs/news_assigned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.00%\n",
      "F1 Score: 75.16%\n",
      "Precision: 75.50%\n",
      "Recall: 76.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (news_assigned['label'] == news_assigned['Predicted Topic']).mean()\n",
    "\n",
    "f1 = f1_score(\n",
    "    news_assigned['label'], \n",
    "    news_assigned['Predicted Topic'], \n",
    "    average='weighted', \n",
    "    zero_division=0\n",
    ")\n",
    "precision = precision_score(\n",
    "    news_assigned['label'], \n",
    "    news_assigned['Predicted Topic'], \n",
    "    average='weighted', \n",
    "    zero_division=0\n",
    ")\n",
    "recall = recall_score(\n",
    "    news_assigned['label'], \n",
    "    news_assigned['Predicted Topic'], \n",
    "    average='weighted', \n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

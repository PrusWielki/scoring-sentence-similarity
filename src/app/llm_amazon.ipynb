{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_array(path):\n",
    "  data = []\n",
    "  with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "      json_object = json.loads(line.strip())\n",
    "      data.append(json_object)\n",
    "  return data\n",
    "\n",
    "dataset_path = '../../datasets/amazon_reviews/'\n",
    "data_path = dataset_path + \"Musical_Instruments.json\"\n",
    "\n",
    "data = read_json_array(data_path)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews = pd.DataFrame()\n",
    "amazon_reviews['Reviews'] = df['reviewText'].copy()\n",
    "amazon_reviews['Ratings'] = df['overall'].copy()\n",
    "amazon_reviews = amazon_reviews.sample(n=10000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/dhv__9sj0yv1kz0pfv2ds9nh0000gn/T/ipykernel_1168/2721138275.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"gemma2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Creating Topics for batches of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics_in_batches(amazon_reviews, batch_size=100, llm=None):\n",
    "    \"\"\"\n",
    "    Generate topics from Amazon reviews in batches to handle large datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    amazon_reviews (pd.DataFrame): DataFrame containing Amazon reviews\n",
    "    batch_size (int): Number of reviews to process in each batch\n",
    "    llm: The language model instance to use for generating topics\n",
    "    \n",
    "    Returns:\n",
    "    list: List of lists containing topics for each batch\n",
    "    \"\"\"\n",
    "    if llm is None:\n",
    "        raise ValueError(\"LLM instance must be provided\")\n",
    "    \n",
    "    all_batch_topics = []\n",
    "    total_reviews = len(amazon_reviews)\n",
    "    \n",
    "    # Process reviews in batches\n",
    "    for start_idx in tqdm(range(0, total_reviews, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, total_reviews)\n",
    "        batch_reviews = amazon_reviews.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Generate prompt for current batch\n",
    "        prompt_labels_generator = f'''You are provided with amazon reviews and helping to cluster the reviews based on the topics.\n",
    "Please create topics based on the reviews provided. Keep the topics general and not specific to the reviews. \n",
    "DO NOT include any specific details. NO TOPICS LIKE  DJ Equipment, Guitar, Piano, etc. Topics should be general and helpful for business steakholders to understand what people are thinking about the products,\n",
    "Amazon Reviews: {batch_reviews['Reviews'].tolist()}\n",
    "Please return only in CSV format with the following structure:\n",
    "Topic1, Topic2, Topic3, Topic4, Topic5,...\n",
    "Return only the topics in CSV format and nothing else.\n",
    "'''\n",
    "\n",
    "        # Get topics for current batch\n",
    "        result = llm.invoke(prompt_labels_generator, temperature=0.0)\n",
    "        \n",
    "        # Convert CSV string to list of topics\n",
    "        batch_topics = [topic.strip() for topic in result.split(',')]\n",
    "        all_batch_topics.append(batch_topics)\n",
    "        \n",
    "        print(f\"Processed batch {len(all_batch_topics)}: reviews {start_idx} to {end_idx}\")\n",
    "    \n",
    "    return all_batch_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:04<08:06,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1: reviews 0 to 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:09<07:51,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 2: reviews 10 to 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:13<07:23,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 3: reviews 20 to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:19<08:05,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 4: reviews 30 to 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:23<07:03,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 5: reviews 40 to 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:25<05:58,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 6: reviews 50 to 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:28<05:15,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 7: reviews 60 to 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:30<04:44,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 8: reviews 70 to 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:34<05:16,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 9: reviews 80 to 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:39<05:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 10: reviews 90 to 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:43<05:41,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 11: reviews 100 to 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:46<05:14,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 12: reviews 110 to 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:49<05:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 13: reviews 120 to 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:52<04:43,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 14: reviews 130 to 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:57<05:28,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 15: reviews 140 to 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:03<06:02,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 16: reviews 150 to 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:08<06:21,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 17: reviews 160 to 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:11<05:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 18: reviews 170 to 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:18<06:44,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 19: reviews 180 to 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:20<05:42,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 20: reviews 190 to 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:24<05:20,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 21: reviews 200 to 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:27<04:46,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 22: reviews 210 to 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:31<04:53,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 23: reviews 220 to 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:34<04:27,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 24: reviews 230 to 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:40<05:27,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 25: reviews 240 to 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:47<06:24,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 26: reviews 250 to 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:50<05:27,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 27: reviews 260 to 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:54<05:24,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 28: reviews 270 to 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:59<05:10,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 29: reviews 280 to 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:03<05:12,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 30: reviews 290 to 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:06<04:31,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 31: reviews 300 to 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:09<04:13,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 32: reviews 310 to 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:13<04:13,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 33: reviews 320 to 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:15<03:32,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 34: reviews 330 to 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:19<03:39,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 35: reviews 340 to 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:22<03:32,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 36: reviews 350 to 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:27<03:55,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 37: reviews 360 to 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:31<03:59,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 38: reviews 370 to 380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:37<04:34,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 39: reviews 380 to 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:45<05:30,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 40: reviews 390 to 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:49<05:11,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 41: reviews 400 to 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:54<04:45,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 42: reviews 410 to 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:58<04:29,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 43: reviews 420 to 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [03:00<03:50,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 44: reviews 430 to 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [03:05<03:58,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 45: reviews 440 to 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [03:07<03:09,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 46: reviews 450 to 460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [03:18<05:05,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 47: reviews 460 to 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [03:24<05:07,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 48: reviews 470 to 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [03:29<04:37,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 49: reviews 480 to 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [03:33<04:24,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 50: reviews 490 to 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [03:36<03:45,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 51: reviews 500 to 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [03:40<03:21,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 52: reviews 510 to 520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [03:43<02:57,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 53: reviews 520 to 530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [03:50<03:39,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 54: reviews 530 to 540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [03:54<03:35,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 55: reviews 540 to 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [03:59<03:30,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 56: reviews 550 to 560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [04:03<03:12,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 57: reviews 560 to 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [04:05<02:43,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 58: reviews 570 to 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [04:11<02:56,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 59: reviews 580 to 590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [04:15<02:46,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 60: reviews 590 to 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [04:17<02:17,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 61: reviews 600 to 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [04:20<02:16,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 62: reviews 610 to 620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [04:25<02:19,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 63: reviews 620 to 630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [04:33<03:02,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 64: reviews 630 to 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [04:36<02:36,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 65: reviews 640 to 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [04:47<03:38,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 66: reviews 650 to 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [04:50<03:05,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 67: reviews 660 to 670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [04:54<02:41,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 68: reviews 670 to 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [04:58<02:23,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 69: reviews 680 to 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [05:02<02:15,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 70: reviews 690 to 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [05:07<02:14,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 71: reviews 700 to 710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [05:13<02:17,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 72: reviews 710 to 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [05:15<01:50,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 73: reviews 720 to 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [05:17<01:28,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 74: reviews 730 to 740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [05:20<01:28,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 75: reviews 740 to 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [05:22<01:13,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 76: reviews 750 to 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [05:29<01:34,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 77: reviews 760 to 770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [05:33<01:31,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 78: reviews 770 to 780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [05:36<01:19,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 79: reviews 780 to 790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [05:39<01:09,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 80: reviews 790 to 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [05:41<01:01,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 81: reviews 800 to 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [05:45<00:57,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 82: reviews 810 to 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [05:48<00:56,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 83: reviews 820 to 830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [05:51<00:52,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 84: reviews 830 to 840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [05:55<00:49,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 85: reviews 840 to 850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [06:00<00:52,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 86: reviews 850 to 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [06:04<00:49,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 87: reviews 860 to 870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [06:11<01:00,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 88: reviews 870 to 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [06:19<01:05,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 89: reviews 880 to 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [06:23<00:52,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 90: reviews 890 to 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [06:26<00:40,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 91: reviews 900 to 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [06:30<00:34,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 92: reviews 910 to 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [06:36<00:33,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 93: reviews 920 to 930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [06:38<00:24,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 94: reviews 930 to 940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [06:41<00:19,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 95: reviews 940 to 950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [06:47<00:17,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 96: reviews 950 to 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [06:51<00:13,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 97: reviews 960 to 970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [06:55<00:08,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 98: reviews 970 to 980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [06:57<00:03,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 99: reviews 980 to 990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:01<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 100: reviews 990 to 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topics_by_batch = generate_topics_in_batches(amazon_reviews.sample(1000, random_state=42), batch_size=10, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_topics = list(set([topic for batch in topics_by_batch for topic in batch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Technical Aspects',\n",
       " 'User Experience',\n",
       " 'Sound & Performance',\n",
       " 'Guitar Straps',\n",
       " 'Sound/Performance',\n",
       " 'Aesthetics',\n",
       " 'Guitar Effects Pedals',\n",
       " 'Impedance Matching',\n",
       " 'Customer Experience',\n",
       " 'Product Durability',\n",
       " 'Performance & Functionality',\n",
       " 'Price Value',\n",
       " 'Durability & Performance',\n",
       " 'Features',\n",
       " 'Value',\n",
       " 'Comfort',\n",
       " 'Shipping & Delivery',\n",
       " 'Microphone Sensitivity',\n",
       " 'Quality',\n",
       " 'Learning Curve',\n",
       " 'Size',\n",
       " 'Usage Experience',\n",
       " 'Vocal Harmonizers',\n",
       " 'Product Quality',\n",
       " 'Size & Portability',\n",
       " 'Value for Money',\n",
       " 'Price',\n",
       " 'Performance Issues',\n",
       " 'Guitar Amplifiers',\n",
       " 'Usage',\n",
       " 'Aesthetics & Comfort',\n",
       " 'Performance',\n",
       " 'Delivery Experience',\n",
       " 'Customer Satisfaction',\n",
       " 'Installation & Setup',\n",
       " 'Target Audience',\n",
       " 'Comfort/Design',\n",
       " 'Fit & Functionality',\n",
       " 'Brand Perception',\n",
       " 'Experience',\n",
       " 'Cello Pickup Installation',\n",
       " 'Shipping Experience',\n",
       " 'Compatibility',\n",
       " 'Customer Service',\n",
       " 'Product Performance',\n",
       " 'Usability',\n",
       " 'Quality & Durability',\n",
       " 'Performance Quality',\n",
       " 'Shipping & Packaging',\n",
       " 'Customer Support',\n",
       " 'Product Value',\n",
       " 'Guitar Pickups',\n",
       " 'Durability',\n",
       " 'Aesthetics & Design',\n",
       " 'Microphones',\n",
       " 'Microphone Performance',\n",
       " 'Product Functionality',\n",
       " 'Functionality & Usability',\n",
       " 'Functionality',\n",
       " 'Size & Fit',\n",
       " 'Sound',\n",
       " 'Sound Quality',\n",
       " 'Versatility',\n",
       " 'Age Appropriateness',\n",
       " 'Design & Aesthetics',\n",
       " 'Emotional Response',\n",
       " 'Product Aesthetics',\n",
       " 'Portability',\n",
       " 'Ease of Use',\n",
       " 'Gift Giving',\n",
       " 'Packaging & Shipping']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Combining all topics to a smaller more general subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_merge_topics = f'''You are provided with topics generated from Amazon reviews.\n",
    "Please merge the topics into a smaller number of topics. The topics should be VERY GENERAL and NOT specific. Do not output more than 15 topics. \n",
    "Merge/combine topics that are similar or related.\n",
    "Topics: {all_unique_topics}\n",
    "Please return only in CSV format with the following structure:\n",
    "MergedTopic1, MergedTopic2, MergedTopic3, MergedTopic4, MergedTopic5,...\n",
    "Return only the merged topics in CSV format and nothing else.\n",
    "'''\n",
    "\n",
    "# Get merged topics\n",
    "proper_topics_str = llm.invoke(prompt_merge_topics, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technical Aspects', 'User Experience', 'Sound & Performance', 'Aesthetics', 'Durability', 'Price & Value', 'Customer Experience', 'Size & Portability', 'Functionality & Usability', 'Shipping & Delivery', 'Brand Perception', 'Product Quality', 'Comfort & Design', 'Learning Curve', 'Target Audience', 'Usage Experience', 'Gift Giving', 'Emotional Response', 'Compatibility', 'Customer Service']\n"
     ]
    }
   ],
   "source": [
    "proper_topics = [topic.strip() for topic in proper_topics_str.split(',')]\n",
    "print(proper_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Assigning batches of dataset to Topics Generated in Step 2 and sentiment of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics_in_batches(input_df, topics, batch_size, llm=None):\n",
    "    \"\"\"\n",
    "    Assign topics and sentiment to Amazon reviews in batches and update DataFrame directly.\n",
    "\n",
    "    Parameters:\n",
    "    input_df (pd.DataFrame): DataFrame containing Amazon reviews\n",
    "    topics (str): String of topics to assign from\n",
    "    batch_size (int): Number of reviews to process in each batch\n",
    "    llm: The language model instance to use for assigning topics\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with topic and sentiment assignments\n",
    "    \"\"\"\n",
    "    if llm is None:\n",
    "        raise ValueError(\"LLM instance must be provided\")\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Initialize Topic and Sentiment columns with 'Unknown'\n",
    "    df['Topic'] = 'Unknown'\n",
    "    df['Sentiment'] = 'Unknown'\n",
    "\n",
    "    total_reviews = len(df)\n",
    "\n",
    "    # Process reviews in batches with progress bar\n",
    "    for start_idx in tqdm(range(0, total_reviews, batch_size), desc=\"Assigning topics\"):\n",
    "        end_idx = min(start_idx + batch_size, total_reviews)\n",
    "        batch_reviews_list = df.iloc[start_idx:end_idx]\n",
    "        batch_reviews = \" \".join([f\"Comment {i + 1}: {review},\" for i, review in enumerate(batch_reviews_list['Reviews'])])\n",
    "        \n",
    "        # Generate prompt for current batch\n",
    "        prompt_assigning_prompt = f'''You are provided with amazon reviews and helping to cluster the reviews based on the topics.\n",
    "Please assign the review to the topics provided. Return only the name of the topic and sentiment for the review. Sentiment can be only Positive, Negative or Neutral.\n",
    "Amazon Review: {batch_reviews}\n",
    "Topics: {topics}\n",
    "Please return in JSON format only topics and sentiment for respective reviews and nothing else. Do not use triple backtick blocks. Only output exactly as on the example below:\n",
    "Example: Having an input of Review1, Review2, Review3, Review4\n",
    "Output: [{{\"topic\": \"Topic1\", \"sentiment\": \"Sentiment1\"}}, {{\"topic\": \"Topic2\", \"sentiment\": \"Sentiment2\"}}, {{\"topic\": \"Topic3\", \"sentiment\": \"Sentiment3\"}}]\n",
    "'''\n",
    "\n",
    "        # Get assignments for current batch\n",
    "        result = llm.invoke(prompt_assigning_prompt, temperature=0.0)\n",
    "\n",
    "        try:\n",
    "            # Parse JSON response\n",
    "            assignments = json.loads(result)\n",
    "\n",
    "            # Update DataFrame directly using indices\n",
    "            for idx, assignment in enumerate(assignments):\n",
    "                current_idx = start_idx + idx\n",
    "                if current_idx < total_reviews:\n",
    "                    topic = assignment.get('topic', 'Unknown')\n",
    "                    sentiment = assignment.get('sentiment', 'Unknown')\n",
    "\n",
    "                    df.at[current_idx, 'Topic'] = topic\n",
    "                    df.at[current_idx, 'Sentiment'] = sentiment\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"\\nError parsing JSON for batch starting at index {start_idx}: {str(e)}\")\n",
    "            print(f\"Raw response: {result}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\nUnexpected error processing batch starting at index {start_idx}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   0%|          | 1/2000 [00:06<3:22:40,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 0: Expecting value: line 1 column 299 (char 298)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Negative\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   1%|          | 23/2000 [02:11<3:00:02,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 110: Expecting value: line 1 column 284 (char 283)\n",
      "Raw response: [{\"topic\": \"Durability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Learning Curve\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   7%|▋         | 135/2000 [13:54<2:57:49,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 670: Expecting value: line 1 column 240 (char 239)\n",
      "Raw response: [{\"topic\": \"Customer Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   9%|▉         | 175/2000 [18:09<2:49:06,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 870: Expecting value: line 1 column 220 (char 219)\n",
      "Raw response: [{\"topic\": \"Technical Aspects\", \"sentiment\": \"Negative\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   9%|▉         | 184/2000 [19:06<3:08:14,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 915: Expecting value: line 1 column 226 (char 225)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Customer Experience\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:   9%|▉         | 185/2000 [19:13<3:11:17,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 920: Expecting value: line 1 column 283 (char 282)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Neutral\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  10%|▉         | 191/2000 [19:50<3:05:12,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 950: Expecting value: line 1 column 232 (char 231)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Negative\"}, {\"topic\": \"Size & Portability\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  11%|█▏        | 225/2000 [23:36<3:00:32,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1120: Expecting value: line 1 column 237 (char 236)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  12%|█▏        | 238/2000 [24:55<2:56:37,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1185: Expecting value: line 1 column 241 (char 240)\n",
      "Raw response: [{\"topic\": \"Technical Aspects\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Customer Experience\", \"sentiment\": \"Positive\"}, ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  13%|█▎        | 251/2000 [26:05<2:32:28,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1250: Expecting value: line 1 column 226 (char 225)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  14%|█▍        | 284/2000 [29:24<2:42:19,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1415: Expecting value: line 1 column 229 (char 228)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  19%|█▉        | 387/2000 [39:48<2:50:41,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1930: Expecting value: line 1 column 225 (char 224)\n",
      "Raw response: [{\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  20%|█▉        | 399/2000 [41:02<2:36:44,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 1990: Expecting value: line 1 column 231 (char 230)\n",
      "Raw response: [{\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  21%|██        | 419/2000 [43:20<2:31:32,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 2090: Expecting value: line 1 column 226 (char 225)\n",
      "Raw response: [{\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  25%|██▍       | 498/2000 [52:04<2:50:12,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 2485: Expecting value: line 1 column 293 (char 292)\n",
      "Raw response: [{\"topic\": \"Technical Aspects\", \"sentiment\": \"Negative\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Negative\"}, {\"topic\": \"Size & Portability\", \"sentiment\": \"Negative\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  26%|██▌       | 511/2000 [53:27<2:42:53,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 2550: Expecting value: line 1 column 237 (char 236)\n",
      "Raw response: [{\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Customer Experience\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  30%|███       | 601/2000 [1:02:46<2:24:20,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 3000: Expecting value: line 1 column 290 (char 289)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  32%|███▏      | 635/2000 [1:06:19<2:20:28,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 3170: Expecting value: line 1 column 277 (char 276)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  36%|███▋      | 728/2000 [1:15:47<1:57:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 3635: Expecting value: line 1 column 228 (char 227)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Size & Portability\", \"sentiment\": \"Positive\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  40%|████      | 802/2000 [1:23:51<1:58:52,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 4005: Expecting value: line 1 column 238 (char 237)\n",
      "Raw response: [{\"topic\": \"Size & Portability\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  49%|████▊     | 973/2000 [1:41:04<1:30:12,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 4860: Expecting value: line 1 column 226 (char 225)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Durability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  50%|█████     | 1000/2000 [1:43:51<1:47:18,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 4995: Expecting value: line 1 column 288 (char 287)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  51%|█████     | 1023/2000 [1:46:24<1:36:17,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 5110: Expecting value: line 1 column 278 (char 277)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Learning Curve\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Compatibility\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"},  ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  52%|█████▏    | 1045/2000 [1:48:44<1:28:06,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 5220: Expecting value: line 1 column 238 (char 237)\n",
      "Raw response: [{\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"}, {\"topic\": \"Technical Aspects\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Comfort & Design\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  53%|█████▎    | 1066/2000 [1:51:10<1:40:36,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 5325: Expecting value: line 1 column 295 (char 294)\n",
      "Raw response: [{\"topic\": \"Customer Experience\", \"sentiment\": \"Negative\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Technical Aspects\", \"sentiment\": \"Negative\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Neutral\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  61%|██████    | 1218/2000 [2:07:04<1:16:27,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 6085: Expecting ':' delimiter: line 1 column 316 (char 315)\n",
      "Raw response: [{\"topic\": \"Brand Perception\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Neutral\"}, {\"topic\": \"Customer Experience\", \"sentiment\": \"Negative\"}, {\"topic\": \"Shipping & Delivery\", \"sentiment\": \"Positive\", \"Usage Experience\", \"sentiment\": \"Positive\"}] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  64%|██████▍   | 1282/2000 [2:13:39<1:05:48,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 6405: Expecting value: line 1 column 292 (char 291)\n",
      "Raw response: [{\"topic\": \"User Experience\", \"sentiment\": \"Positive\"}, {\"topic\": \"Price & Value\", \"sentiment\": \"Positive\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Positive\"}, {\"topic\": \"Functionality & Usability\", \"sentiment\": \"Positive\"}, {\"topic\": \"Customer Experience\", \"sentiment\": \"Negative\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  69%|██████▉   | 1387/2000 [2:24:55<1:03:04,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error parsing JSON for batch starting at index 6930: Expecting value: line 1 column 271 (char 270)\n",
      "Raw response: [{\"topic\": \"Technical Aspects\", \"sentiment\": \"Positive\"}, {\"topic\": \"Product Quality\", \"sentiment\": \"Negative\"}, {\"topic\": \"Durability\", \"sentiment\": \"Negative\"}, {\"topic\": \"Sound & Performance\", \"sentiment\": \"Negative\"}, {\"topic\": \"Aesthetics\", \"sentiment\": \"Neutral\"},] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning topics:  73%|███████▎  | 1463/2000 [2:33:05<56:11,  6.28s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m amazon_reviews_with_topics \u001b[38;5;241m=\u001b[39m \u001b[43massign_topics_in_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamazon_reviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproper_topics\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 43\u001b[0m, in \u001b[0;36massign_topics_in_batches\u001b[0;34m(input_df, topics, batch_size, llm)\u001b[0m\n\u001b[1;32m     33\u001b[0m         prompt_assigning_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mYou are provided with amazon reviews and helping to cluster the reviews based on the topics.\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mPlease assign the reviews to the topics provided. Return only the name of the topic and sentiment for the respective reviews. Sentiment can be only Positive, Negative or Neutral.\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124mAmazon Reviews: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_reviews\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124mOutput: [\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# Get assignments for current batch\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_assigning_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;66;03m# Parse JSON response\u001b[39;00m\n\u001b[1;32m     47\u001b[0m             assignments \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(result)\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:390\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    388\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    402\u001b[0m     )\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:755\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    749\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    754\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m     ]\n\u001b[0;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 779\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_community/llms/ollama.py:437\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 437\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_community/llms/ollama.py:349\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    342\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[1;32m    348\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_stream_response_to_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/langchain_community/llms/ollama.py:194\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    188\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    193\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[1;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[1;32m    196\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    197\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    199\u001b[0m     )\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/requests/utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[0;34m(iterator, r)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 572\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/urllib3/response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/urllib3/response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/githubRepos/scoring-sentence-similarity/llm_venv/lib/python3.11/site-packages/urllib3/response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "amazon_reviews_with_topics = assign_topics_in_batches(\n",
    "    amazon_reviews,\n",
    "    topics=str(proper_topics),\n",
    "    batch_size=5,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amazon_reviews_with_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mamazon_reviews_with_topics\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'amazon_reviews_with_topics' is not defined"
     ]
    }
   ],
   "source": [
    "amazon_reviews_with_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews_with_topics.to_csv('outputs/amazon_reviews_with_topics_10000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "Learning Experience    44\n",
       "User Satisfaction      19\n",
       "Product Quality         6\n",
       "Unknown                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_with_topics['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews_with_topics.to_excel('outputs/amazon_reviews_with_topics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Positive    58\n",
       "Negative     7\n",
       "Neutral      4\n",
       "Unknown      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_with_topics['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Not really current.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good reference book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I'm only giving this book three stars because ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Learning Experience</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>still can't crochet to save my life</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Learning Experience</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>:-)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Learning Experience</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Great book I just wish the pics were more in c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I TRIED BUT I AM BETTER AT KNITTING</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Learning Experience</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>still learning but having fun doing it</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Learning Experience</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Thanks</td>\n",
       "      <td>5.0</td>\n",
       "      <td>User Satisfaction</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>I have never really used it. I don't really ge...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>User Satisfaction</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Package arrived in the time frame that was gua...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>good book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Reviews  Ratings  \\\n",
       "11                                Not really current.      3.0   \n",
       "14                                Good reference book      5.0   \n",
       "17  I'm only giving this book three stars because ...      3.0   \n",
       "23                still can't crochet to save my life      4.0   \n",
       "26                                                :-)      5.0   \n",
       "45  Great book I just wish the pics were more in c...      5.0   \n",
       "47                I TRIED BUT I AM BETTER AT KNITTING      5.0   \n",
       "52             still learning but having fun doing it      5.0   \n",
       "62                                             Thanks      5.0   \n",
       "67  I have never really used it. I don't really ge...      2.0   \n",
       "68  Package arrived in the time frame that was gua...      2.0   \n",
       "69                                          good book      5.0   \n",
       "\n",
       "                  Topic Sentiment  \n",
       "11      Product Quality  Negative  \n",
       "14      Product Quality   Neutral  \n",
       "17  Learning Experience  Negative  \n",
       "23  Learning Experience  Negative  \n",
       "26  Learning Experience   Neutral  \n",
       "45      Product Quality  Negative  \n",
       "47  Learning Experience  Negative  \n",
       "52  Learning Experience   Neutral  \n",
       "62    User Satisfaction   Neutral  \n",
       "67    User Satisfaction  Negative  \n",
       "68      Product Quality  Negative  \n",
       "69              Unknown   Unknown  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_with_topics[amazon_reviews_with_topics['Sentiment'] != 'Positive']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
